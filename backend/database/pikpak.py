import json
import os
from typing import Dict, List, Any, Optional
from datetime import datetime
from pikpakapi import PikPakApi
from apis.pikpak_api import PikPakService
import asyncio


class PikPakDatabase:
    """PikPak æ•°æ®åº“ç®¡ç†"""

    def __init__(self, db_path: str = "data/anime.json"):
        self.db_path = db_path
        self.ensure_db_exists()
        self.service = PikPakService()

    def ensure_db_exists(self):
        """ç¡®ä¿æ•°æ®åº“æ–‡ä»¶å­˜åœ¨"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)

        if not os.path.exists(self.db_path):
            # åˆ›å»ºç©ºçš„æ•°æ®åº“ç»“æ„
            initial_data = {
                "animes": {},
                "metadata": {
                    "created_at": datetime.now().isoformat(),
                    "last_updated": datetime.now().isoformat(),
                },
            }
            self.save_data(initial_data)

    def load_data(self) -> Dict[str, Any]:
        """åŠ è½½æ•°æ®åº“æ•°æ®"""
        try:
            with open(self.db_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"åŠ è½½æ•°æ®åº“å¤±è´¥: {e}")
            return {"animes": {}, "metadata": {}}

    def _upgrade_data_structure(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è°ƒæ•´æ•°æ®ç»“æ„"""
        upgraded_animes = {}

        for folder_id, anime_info in data.get("animes", {}).items():
            # æ•°æ®ç»“æ„
            upgraded_animes[folder_id] = {
                "folder_name": anime_info.get("title", ""),
                "files": [
                    # æ–‡ä»¶åˆ—è¡¨ç»“æ„ç¤ºä¾‹
                    # {
                    #     "file_name": "ç¬¬01è¯.mp4",
                    #     "file_id": "file123",
                    #     "play_url": "https://example.com/play/file123"
                    # }
                ],
                "cover_url": anime_info.get("cover_url", ""),
                "status": anime_info.get("status", "è¿è½½"),
                "summary": anime_info.get("summary", ""),
            }

        return {
            "animes": upgraded_animes,
            "metadata": {
                "created_at": data.get("metadata", {}).get(
                    "created_at", datetime.now().isoformat()
                ),
                "last_updated": datetime.now().isoformat(),
            },
        }

    def save_data(self, data: Dict[str, Any]) -> bool:
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        try:
            data["metadata"]["last_updated"] = datetime.now().isoformat()
            with open(self.db_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"ä¿å­˜æ•°æ®åº“å¤±è´¥: {e}")
            return False

    def get_anime_detail(self, anime_id: str) -> Dict[str, Any]:
        """è·å–åŠ¨æ¼«è¯¦ç»†ä¿¡æ¯"""
        data = self.load_data()
        anime_info = data["animes"].get(anime_id, {})

        if not anime_info:
            return {}

        return {
            "id": anime_id,
            "title": anime_info.get("title", ""),
            "status": anime_info.get("status", "è¿è½½"),
            "summary": anime_info.get("summary", ""),
            "cover_url": anime_info.get("cover_url", ""),
            "updated_at": anime_info.get("updated_at", ""),
        }

    def get_anime_status(self, anime_id: str) -> str:
        """è·å–åŠ¨æ¼«çŠ¶æ€"""
        data = self.load_data()
        anime_info = data["animes"].get(anime_id, {})
        return anime_info.get("status", "è¿è½½")

    async def sync_data(self, client: PikPakApi) -> bool:
        """
        åŒæ­¥æ•°æ®
        """
        try:
            # åŠ è½½æ•°æ®
            data = self.load_data()
            if "animes" not in data:
                print("âŒ æ•°æ®æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘animeså­—æ®µ")
                return

            # è·å–mypack_id
            mypack_id = list(data["animes"].keys())[0]
            anime_folders = data["animes"][mypack_id]

            # api è°ƒç”¨è®¡æ•°
            api_call_count = 0
            api_batch_size = 3
            api_delay = 8

            print(f"ğŸ“Š å¼€å§‹åŒæ­¥æ•°æ®")

            # è·å–äº‘ç«¯ mypackçš„æ‰€æœ‰æ–‡ä»¶å¤¹ id
            cloud_folders = await self.service.get_mypack_folder_list(client)
            # å»ºç«‹äº‘ç«¯æ–‡ä»¶å¤¹æ˜ å°„ {id: id_value}
            cloud_folder_map = {folder["id"]: folder for folder in cloud_folders}
            cloud_folder_ids = set(cloud_folder_map.keys())

            # è·å–æœ¬åœ°å·²æœ‰çš„æ–‡ä»¶åˆ—è¡¨ï¼Œå»ºç«‹IDåˆ°æ’­æ”¾é“¾æ¥çš„æ˜ å°„
            local_folder_ids = set(anime_folders.keys())

            # è®¡ç®—å·®å¼‚
            new_folder_ids = cloud_folder_ids - local_folder_ids  # äº‘ç«¯æœ‰ï¼Œæœ¬åœ°æ²¡æœ‰
            del_folder_ids = local_folder_ids - cloud_folder_ids  # äº‘ç«¯æ²¡æœ‰ï¼Œæœ¬åœ°æœ‰

            # åˆ é™¤æœ¬åœ°å¤šä½™çš„
            for folder_id in del_folder_ids:
                folder_name = anime_folders[folder_id].get("title", "æœªçŸ¥")
                print(f"  â– åˆ é™¤æœ¬åœ°å¤šä½™çš„ {folder_name} æ–‡ä»¶å¤¹")
                del anime_folders[folder_id]

            # å¤„ç†æ–°å¢çš„æ–‡ä»¶å¤¹
            for folder_id in new_folder_ids:
                folder_name = cloud_folder_map[folder_id]["name"]
                print(f"  â• æ–°å¢ {folder_name} æ–‡ä»¶å¤¹")
                anime_folders[folder_id] = {
                    "title": folder_name,
                    "status": "è¿è½½",
                    "files": [],
                    "updated_at": datetime.now().isoformat(),
                    "summary": "",
                    "cover_url": "",
                }

            # å¤„ç†ç›¸åŒçš„æ–‡ä»¶å¤¹
            for folder_id, anime_info in anime_folders.items():

                # è·å–æœ¬åœ°å·²æœ‰çš„æ–‡ä»¶åˆ—è¡¨ï¼Œå»ºç«‹IDåˆ°æ’­æ”¾é“¾æ¥çš„æ˜ å°„
                existing_files = anime_info.get("files", [])
                existing_file_map = {}
                for existing_file in existing_files:
                    file_id = existing_file.get("id")
                    play_url = existing_file.get("play_url")
                    if file_id and play_url:
                        existing_file_map[file_id] = existing_file

                # è·å–æ–‡ä»¶å¤¹å†…çš„æ–‡ä»¶
                folder_result = await self.service.get_folder_files(client, folder_id)

                if not folder_result["success"]:
                    print(f"  âŒ è·å–æ–‡ä»¶å¤¹å†…å®¹å¤±è´¥: {folder_result['message']}")
                    continue

                files = folder_result["files"]

                if not files:
                    print(f"  âš ï¸  æ–‡ä»¶å¤¹ä¸ºç©º")
                    continue

                print(f"  ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")
                result = []

                # ä¸ºæ¯ä¸ªæ–‡ä»¶å¤¹è·å–æ’­æ”¾è¿æ¥
                for file in files:
                    if file["id"] in existing_file_map:
                        # print(f"      â™»ï¸  ä½¿ç”¨æœ¬åœ°å·²æœ‰æ’­æ”¾é“¾æ¥")
                        original_file = existing_file_map[file_id]
                        file_data = {
                            "id": file["id"],
                            "name": file["name"],
                            "play_url": original_file["play_url"],
                        }
                    else:
                        # è·å–æ’­æ”¾è¿æ¥
                        play_url = await self.service.get_video_play_url(
                            file["id"], client
                        )
                        print(f"      ğŸ“¡ æˆåŠŸè·å–æ’­æ”¾é“¾æ¥: {play_url}")
                        api_call_count += 1

                        # æ£€æŸ¥æ˜¯å¦éœ€è¦å»¶æ—¶
                        if api_call_count % api_batch_size == 0:
                            print(
                                f"      â±ï¸  å·²è°ƒç”¨ {api_call_count} æ¬¡APIï¼Œå»¶æ—¶ {api_delay} ç§’..."
                            )
                            await asyncio.sleep(api_delay)

                        file_data = {
                            "id": file["id"],
                            "name": file["name"],
                            "play_url": play_url,
                        }
                    result.append(file_data)

                # æ›´æ–°æ•°æ®
                anime_info["files"] = result

            # ä¿å­˜æ•°æ®
            data["metadata"]["last_updated"] = datetime.now().isoformat()
            self.save_data(data)
            print("âœ… åŒæ­¥æˆåŠŸ")
            return True
        except Exception as e:
            print(f"åŒæ­¥æ•°æ®å¤±è´¥: {e}")
            return False

    # def sync_with_pikpak_folders(self, pikpak_folders: List[Dict]) -> List[Dict]:
    #     """
    #     åŒæ­¥ pikpak æ•°æ®

    #     Args:
    #         pikpak_folders: PikPak æ–‡ä»¶å¤¹åˆ—è¡¨ [{"name": "åŠ¨æ¼«å", "id": "æ–‡ä»¶å¤¹ID"}]

    #     Returns:
    #         åˆå¹¶åçš„åŠ¨æ¼«åˆ—è¡¨
    #     """
    #     result = []

    #     # å¤„ç† PikPak ä¸­çš„æ–‡ä»¶å¤¹
    #     for folder in pikpak_folders:
    #         folder_id = folder["id"]
    #         folder_name = folder["name"]

    #         # è·å–åŠ¨æ¼«è¯¦ç»†ä¿¡æ¯
    #         anime_detail = self.get_anime_detail(folder_id)

    #         # æ–°åŠ¨æ¼«
    #         if not anime_detail:
    #             anime_detail = {
    #                 "id": folder_id,
    #                 "title": folder_name,
    #                 "status": "è¿è½½",
    #                 "summary": "",
    #                 "cover_url": "",
    #                 "updated_at": datetime.now().isoformat(),
    #             }

    #         result.append(
    #             {
    #                 "id": folder_id,
    #                 "title": anime_detail.get("title", folder_name),
    #                 "status": anime_detail.get("status", "è¿è½½"),
    #                 "summary": anime_detail.get("summary", ""),
    #                 "cover_url": anime_detail.get("cover_url", ""),
    #                 "updated_at": anime_detail.get("updated_at", ""),
    #             }
    #         )

    #     print(f"åŒæ­¥å®Œæˆï¼Œå…± {len(result)} ä¸ªåŠ¨æ¼«")
    #     return result

    def get_all_animes(self) -> List[Dict]:
        """è·å–æ‰€æœ‰åŠ¨æ¼«åˆ—è¡¨"""
        data = self.load_data()
        result = []

        for anime_id, anime_info in data["animes"].items():
            result.append(
                {
                    "id": anime_id,
                    "title": anime_info.get("title", ""),
                    "status": anime_info.get("status", "è¿è½½"),
                    "summary": anime_info.get("summary", ""),
                    "cover_url": anime_info.get("cover_url", ""),
                    "updated_at": anime_info.get("updated_at", ""),
                }
            )

        return result

    async def update_anime_info(
        self, anime_id: str, update_data: Dict[str, Any]
    ) -> bool:
        """
        æ›´æ–°åŠ¨æ¼«ä¿¡æ¯
        """
        try:
            # print("å°†è¦æ›´æ–°çš„åŠ¨æ¼«ä¿¡æ¯ï¼š", update_data)
            # åŠ è½½ç°æœ‰æ•°æ®
            db_data = self.load_data()

            # æ£€æŸ¥åŠ¨æ¼«æ˜¯å¦å­˜åœ¨
            if anime_id not in db_data["animes"]:
                print(f"åŠ¨æ¼« {anime_id} ä¸å­˜åœ¨")
                return False

            # è·å–ç°æœ‰åŠ¨æ¼«ä¿¡æ¯
            anime_info = db_data["animes"][anime_id]
            # print("æ›´æ–°å‰çš„åŠ¨æ¼«ä¿¡æ¯ï¼š", anime_info)

            # åªæ›´æ–°ä¼ å…¥çš„å­—æ®µ
            updatable_fields = ["title", "status", "summary", "cover_url"]

            for field in updatable_fields:
                if field in update_data:
                    anime_info[field] = update_data[field]

            # æ›´æ–°æ—¶é—´æˆ³
            anime_info["updated_at"] = datetime.now().isoformat()

            # print("æ›´æ–°åçš„åŠ¨æ¼«ä¿¡æ¯ï¼š", anime_info)

            # ä¿å­˜æ•°æ®
            return self.save_data(db_data)

        except Exception as e:
            print(f"æ›´æ–°åŠ¨æ¼«ä¿¡æ¯å¤±è´¥: {e}")
            return False
